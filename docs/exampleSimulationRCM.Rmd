---
title: "RCM Example Simulation"
author: ""
date: ""
output:
  rmarkdown::html_document:
    code_folding: show
    toc: true
    toc_float: true
    theme: cerulean
    highlight: kate
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, fig.align="center",
                      message = F, warning = F)
```

This document walks through example simulation code used to produce the results obtained in 'A random covariance model for bi-level graphical modeling with application to resting-state fMRI data' submitted to the journal Biometrics. First, we install and load the R package for the submitted manuscript:

```{r}
# Install package
if("rcm" %in% installed.packages() == FALSE) {
devtools::install_github("dilernia/rcm")
}

# Load rcm package
library(rcm)

# Loading other packages
library(tidyverse, quietly = T)
library(kableExtra, quietly = T)
```

## Simulating Data {.tabset .tabset-fade}

We simulate an example data set for $K=8$ total subjects. For each subject, we generate $n=50$ observations for $p=100$ variables with approximately $\rho = 20\%$ of network connections differing from their shared group-level network. 

```{r}
# Generate individual variants with rho=0.2 and errors [-0.1,0.1] for common edges
set.seed(1994)
rm(list = ls())

p <- 100

# common graph 
G <- diag(0,p)

G[1, 2:14] <- G[12, 15] <- G[13, 16] <- G[14, 17] <- G[17, 18] <- 1
G[1, 19] <- G[19, 20] <- G[19, 21] <- G[21, 22:23] <- G[23, 24] <- 1
G[1, 25] <- G[25, 26] <- 1

G[26, 27:33] <- G[33, 34:35] <- 1
G[26, 36] <- G[36, 37:39] <- G[38, 40] <- G[39, 41] <- 1
G[26, 42] <- G[42, 43:44] <- G[44,45] <- 1
G[26, 46] <- G[46, 47] <- G[47, 48] <- G[48, 49:52] <- G[52, 53] <- 1
G[26, 54] <- 1

G[54, 55:62] <- G[59, 63] <- G[60, 64] <- G[61, 65] <- G[62, 66] <- 1
G[54, 67] <- G[67, 68:72] <- 1
G[54, 73] <- G[73, 74:76] <- G[76, 77] <- 1
G[54, 78] <- 1

G[78, 79:82] <- G[81, 83] <- G[82, 84:85] <- 1
G[78, 86] <- 1
G[86, 87:92] <- G[90, 93] <- G[91, 94] <- G[92, 95:96] <- 1
G[86, 97] <- G[97, 98:99] <- G[99, 100] <- 1

temp <- diag(0.5, p) + G * matrix(runif(p * p, 0.5, 1) * sample(c(-1, 1), p * p, replace = TRUE), p, p)
temp2 <- temp + t(temp) + diag(rowSums(G + t(G)) / 2)
any(eigen(temp2, only.values = T)$values <= 0)
Omega0.true <- diag(diag(temp2)^-0.5) %*% temp2 %*% diag(diag(temp2)^-0.5)

# Add/subtract individual specific edges
A <- diag(0, p) 
A[upper.tri(A)] <- 1 
A <- A-G
ind.0 <- which(A == 1)
ind.1 <- which(G == 1)

K <- 8 
Gk <- Omegas.true <- array(0, c(p, p, K))

dif.p <- 0.2 
es <- 0.1

# Generating mechanism 1
for(k in 1:K) {
  ind.ak <- sample(ind.0, round(sum(G) * dif.p))
  ind.dk <- sample(ind.1, round(sum(G) * dif.p))
  ind.sm <- setdiff(ind.1, ind.dk)
  G.ak <- G.dk <- G.sm <- matrix(0, p, p)
  G.ak[ind.ak] <- 1
  G.dk[ind.dk] <- 1
  G.sm[ind.sm] <- 1
  
  temp.k = matrix(0, p, p)
  while(any(eigen(temp.k)$values <= 0)) {
    
    temp.ak <- G.ak * matrix(runif(p * p, 0.5, 1) * sample(c(-1, 1), p * p, replace = TRUE), p, p)
    temp.dk <- G.dk * temp
    temp.sm <- G.sm * matrix(runif(p * p, 0, es) * sample(c(-1, 1),p * p,replace = TRUE), p, p)
    temp.k <- temp + t(temp) - temp.dk - t(temp.dk) + temp.ak + t(temp.ak) + temp.sm + t(temp.sm) + 
      diag(rowSums(G + t(G) + G.ak + t(G.ak) - G.dk - t(G.dk)) / 2)
  }
  Omegas.true[, , k] <- diag(diag(temp.k)^-0.5) %*% temp.k %*% diag(diag(temp.k)^-0.5)
  
  Gk[,,k] <- G + G.ak -G.dk
  
  cat(k,"is done \n")
}

G.true <- G
Gk.true <- Gk

n <- 50

sim.dat <- rep(list(NA),K)
for(k in 1:K) {
  sim.dat[[k]] <- matrix(rnorm(n * p), n, p) %*% chol(solve(Omegas.true[, , k]))
}

```

## Analysis {.tabset .tabset-fade}

We now select the optimal sets of tuning parameters using BIC and a modified BIC and analyze our simulated data set.

```{r, cache = TRUE}
# Parameters to tune: lambda1, lambda2, and lambda3
lam2.cand <- 100
lam3.cand <- 0.0001
lam1.cand <- c(0.0002,0.0006,0.0008,seq(0.001,0.006,by=0.001),0.008,0.01,0.015,0.02)
lams.cand <- expand.grid(lam1.cand,lam2.cand,lam3.cand)

lam2.cand <- 70
lam3.cand <- 0.0001
lam1.cand <- c(0.0002,0.0006,0.0008,seq(0.001,0.006,by=0.001),0.008,0.01,0.015,0.02)
lams.cand <- rbind(lams.cand,expand.grid(lam1.cand,lam2.cand,lam3.cand))

lam2.cand <- 40
lam3.cand <- 0.001
lam1.cand <- c(0.0002,0.0006,0.0008,seq(0.001,0.006,by=0.001),0.008,0.01,0.015,0.02)
lams.cand <- rbind(lams.cand,expand.grid(lam1.cand,lam2.cand,lam3.cand))

colnames(lams.cand) <- c('lam1','lam2','lam3')
nlams <- nrow(lams.cand)

x <- sim.dat

K <- length(x)
p <- ncol(x[[1]])

uptri.mat0 <- diag(0,p)
uptri.mat0[upper.tri(diag(p))] <- 1
uptri.matk <- array(uptri.mat0,c(p, p, K))

Omega0.est <- array(NA,c(p, p, nlams))
Omegas.est <- array(NA,c(p, p, K, nlams))
bic.rc <- mbic.rc <- array(NA, nlams)

for(j in 1:nlams) {
  # Regularizing parameters
  lam1 <- lams.cand[j, 1] * (1 + lams.cand[j, 2])
  lam2 <- lams.cand[j, 2] * K
  lam3 <- lams.cand[j, 3]
  
  # Estimation
  est <- randCov(x, lam1, lam2, lam3)
  
  Omega0 <- est$Omega0
  Omegas <- est$Omegas
  
  Omega0.est[ , , j] <- Omega0
  Omegas.est[ , , , j] <- Omegas
  
  # Calculate BIC
  bic.rc[j] <- bic_cal(x, Omegas)
  mbic.rc[j] <- mbic_cal(x, Omega0, Omegas, lams.cand[j, 2])
  
  # Keep track
  if(j < nlams & lams.cand[j + 1, 2] != lams.cand[j, 2]) {
    cat('lam2 =', lams.cand[j, 2],'is done \n')
  }
  }  # end of loop for all lambdas

# Optimal results for BIC
Omega0.bic <- Omega0.est[ , , which.min(bic.rc)]
Omegas.bic <- Omegas.est[ , , , which.min(bic.rc)]

# Optimal results for modified BIC
Omega0.mbic <- Omega0.est[ , , which.min(mbic.rc)]
Omegas.mbic <- Omegas.est[ , , , which.min(mbic.rc)]
```

## Results {.tabset .tabset-fade}

We summarize the performance of the RCM using both tuning parameter selection approaches. For evaluating performance in terms of edge detection we calculate the true positive rate (TPR), false positive rate (FPR), precision, and F1 scores for the subject-level networks, subscripted with $k$, and cluster-level network, subscripted with $g$. 

```{r}
# Function for summarizing edge detection performances
performanceSummary <- function(Omegaks, Omegags, Omega0ks = Omegas.true, Omega0g = Omega0.true) {

# Calculating Precision Matrix Error, True Positive Rate, and False Positive Rates
subjSum <- sum(sapply(1:K, FUN = function(k){sum((adj(Omegaks[, , k]) +
                                                    adj(Omega0ks[, , k]))[lower.tri(Omega0ks[, , k], diag = FALSE)] == 2)}))
posskEdges <- sum(sapply(1:K, FUN = function(k){sum(adj(Omega0ks[, , k])[lower.tri(Omega0ks[, , k], diag = FALSE)] == 1)}))

TPRk <- subjSum / posskEdges
subjSum0 <- sum(sapply(1:K, FUN = function(k){sum((-1*adj(Omegaks[, , k]) +
                                                     adj(Omega0ks[, , k]))[lower.tri(Omega0ks[, , k], diag = FALSE)] == -1)}))
possk0s <- sum(sapply(1:K, FUN = function(k){sum(adj(Omega0ks[, , k])[lower.tri(Omega0ks[, , k], diag = FALSE)] == 0)}))

FPRk <- subjSum0 / possk0s

PrecisionK <- subjSum / (subjSum + subjSum0)

F1k <- 2*(PrecisionK*TPRk) / (PrecisionK + TPRk)

  grpSum <- sum((adj(Omegags) + adj(Omega0g))[lower.tri(Omega0g, diag = FALSE)] == 2)
  possgEdges <- sum(sapply(1:G, FUN = function(g){sum(adj(Omega0g)[lower.tri(Omega0g, diag = FALSE)] == 1)}))
  TPRg <- grpSum / possgEdges
  grpSum0 <- sum((-1*adj(Omegags) + adj(Omega0g))[lower.tri(Omega0g, diag = FALSE)] == -1)
  possg0s <- sum(adj(Omega0g)[lower.tri(Omega0g, diag = FALSE)] == 0)

  PrecisionG <- grpSum / (grpSum + grpSum0)

  F1g <- 2*(PrecisionG*TPRg) / (PrecisionG + TPRg)

  FPRg <- grpSum0 / possg0s

return(data.frame(TPRk = TPRk, FPRk = FPRk,
                  PrecisionK = PrecisionK, F1k = F1k,
                  TPRg = TPRg, FPRg = FPRg, PrecisionG = PrecisionG, F1g = F1g))
}
```

### BIC

```{r}
performanceSummary(Omegaks = Omegas.bic, Omegag = Omega0.bic) %>% 
  knitr::kable(digits = 3, row.names = F) %>% kable_styling(bootstrap_options = c("hover", "responsive"))
```

### Modified BIC

```{r}
performanceSummary(Omegaks = Omegas.mbic, Omegag = Omega0.mbic) %>% 
  knitr::kable(digits = 3, row.names = F) %>% kable_styling(bootstrap_options = c("hover", "responsive"))
```
